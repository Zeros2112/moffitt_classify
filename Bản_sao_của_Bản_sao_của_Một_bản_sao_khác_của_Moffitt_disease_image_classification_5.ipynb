{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYJqjq66JVQQ"
      },
      "source": [
        "# Transfer learning with disease and non disease data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oWuHhhcJVQQ"
      },
      "source": [
        "### Import tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioLbtB3uGKPX",
        "outputId": "1e353d73-af1e-44c7-88a4-ba7c1cecb96b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjfMJAHPJVQR"
      },
      "source": [
        "### Import modules and download the diseases and none diseases dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y23ucAFLoHop"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from shutil import copyfile\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4iI7buApqQK",
        "outputId": "602d1c79-b76e-4901-a849-e086ee1a69de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcoo5Zv7p2Xb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set the path to your desired directory\n",
        "new_directory_path = '/content/drive/MyDrive/moffitt/'\n",
        "\n",
        "# Change the current working directory\n",
        "os.chdir(new_directory_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mJMjnuNNOWw",
        "outputId": "6cbae4d5-7b8e-46b3-cd0b-fc1cd9f0b91a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data_file_name = \"moffitt.zip\"\n",
        "download_dir = '/tmp/'\n",
        "zip_ref = zipfile.ZipFile(data_file_name, 'r')\n",
        "zip_ref.extractall(download_dir)\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNVXCUNUJVQR"
      },
      "source": [
        "Check that the dataset has the expected number of examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "AwMoZHxWOynx",
        "outputId": "c77dadc8-2cc5-42af-e27e-a594597ac453"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of diseases images: 20\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/tmp/moffitt/classify_cytology/no_diseases/'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-fc30dd589520>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of diseases images:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/tmp/moffitt/classify_cytology/diseases/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of no diseases images:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/tmp/moffitt/classify_cytology/no_diseases/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/moffitt/classify_cytology/no_diseases/'"
          ]
        }
      ],
      "source": [
        "print(\"Number of diseases images:\",len(os.listdir('/tmp/moffitt/classify_cytology/diseases/')))\n",
        "print(\"Number of no diseases images:\", len(os.listdir('/tmp/moffitt/classify_cytology/no_diseases/')))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qId5WmwCUVpb",
        "outputId": "bd445c51-4102-4d76-92f4-5360b91ccba7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directories deleted successfully.\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "try:\n",
        "    shutil.rmtree('/tmp/diseases-v-nondiseases')\n",
        "    print(\"Directories deleted successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Directories not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0riaptkJVQR"
      },
      "source": [
        "Create some folders that will store the training and test data.\n",
        "- There will be a training folder and a testing folder.\n",
        "- Each of these will have a subfolder for diseases and another subfolder for none diseases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qygIo4W5O1hQ"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    os.mkdir('/tmp/diseases-v-nondiseases')\n",
        "    os.mkdir('/tmp/diseases-v-nondiseases/training')\n",
        "    os.mkdir('/tmp/diseases-v-nondiseases/testing')\n",
        "    os.mkdir('/tmp/diseases-v-nondiseases/training/diseases')\n",
        "    os.mkdir('/tmp/diseases-v-nondiseases/training/non_diseases')\n",
        "    os.mkdir('/tmp/diseases-v-nondiseases/testing/diseases')\n",
        "    os.mkdir('/tmp/diseases-v-nondiseases/testing/non_diseases')\n",
        "except OSError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZHD_c-sJVQR"
      },
      "source": [
        "### Split data into training and test sets\n",
        "\n",
        "- The following code put first checks if an image file is empty (zero length)\n",
        "- Of the files that are not empty, it puts 90% of the data into the training set, and 10% into the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M90EiIu0O314",
        "outputId": "459e2f59-d867-4f21-dd13-28e78edd159e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of images: 2\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from shutil import copyfile\n",
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "    files = []\n",
        "    for filename in os.listdir(SOURCE):\n",
        "        file = SOURCE + filename\n",
        "        if os.path.getsize(file) > 0:\n",
        "            files.append(filename)\n",
        "        else:\n",
        "            print(filename + \" is zero length, so ignoring.\")\n",
        "\n",
        "    training_length = int(len(files) * SPLIT_SIZE)\n",
        "    testing_length = int(len(files) - training_length)\n",
        "    shuffled_set = random.sample(files, len(files))\n",
        "    training_set = shuffled_set[0:training_length]\n",
        "    testing_set = shuffled_set[training_length:]\n",
        "\n",
        "    for filename in training_set:\n",
        "        this_file = SOURCE + filename\n",
        "        destination = TRAINING + filename\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "    for filename in testing_set:\n",
        "        this_file = SOURCE + filename\n",
        "        destination = TESTING + filename\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "\n",
        "DISEASES_SOURCE_DIR = \"/tmp/moffitt/classify_cytology/diseases/\"\n",
        "TRAINING_DISEASES_DIR = \"/tmp/diseases-v-nondiseases/training/diseases/\"\n",
        "TESTING_DISEASES_DIR = \"/tmp/diseases-v-nondiseases/testing/diseases/\"\n",
        "NO_DISEASES_SOURCE_DIR = \"/tmp/moffitt/classify_cytology/no_diseases/\"\n",
        "TRAINING_NO_DISEASES_DIR = \"/tmp/diseases-v-nondiseases/training/non_diseases/\"\n",
        "TESTING_NO_DISEASES_DIR = \"/tmp/diseases-v-nondiseases/testing/non_diseases/\"\n",
        "\n",
        "split_size = 0.95\n",
        "split_data(DISEASES_SOURCE_DIR, TRAINING_DISEASES_DIR, TESTING_DISEASES_DIR, split_size)\n",
        "split_data(NO_DISEASES_SOURCE_DIR, TRAINING_NO_DISEASES_DIR, TESTING_NO_DISEASES_DIR, split_size)\n",
        "print(\"Number of images:\",len(os.listdir('/tmp/diseases-v-nondiseases/training/')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "nfbo1HTqvBts",
        "outputId": "30d367af-6918-4a25-ed69-76460caacf27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/moffitt/training1/'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set your source and destination directories\n",
        "source_directory = '/tmp/diseases-v-nondiseases/testing/'\n",
        "destination_directory = '/content/drive/MyDrive/moffitt/testing1/'\n",
        "\n",
        "# Copy files from source to destination\n",
        "shutil.copytree(source_directory, destination_directory)\n",
        "\n",
        "# Repeat for the training directory\n",
        "source_directory = '/tmp/diseases-v-nondiseases/training/'\n",
        "destination_directory = '/content/drive/MyDrive/moffitt/training1/'\n",
        "\n",
        "shutil.copytree(source_directory, destination_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MclCJAMitHga",
        "outputId": "c3a6d333-03ac-429b-bd21-66477cdce92b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training diseases images 1603\n",
            "Number of training no diseases images 1517\n",
            "Number of testing diseases images 85\n",
            "Number of testing no diseases images 80\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of training diseases images\", len(os.listdir('/content/drive/MyDrive/moffitt/training1/diseases/')))\n",
        "print(\"Number of training no diseases images\", len(os.listdir('/content/drive/MyDrive/moffitt/training1/non_diseases/')))\n",
        "print(\"Number of testing diseases images\", len(os.listdir('/content/drive/MyDrive/moffitt/testing1/diseases/')))\n",
        "print(\"Number of testing no diseases images\", len(os.listdir('/content/drive/MyDrive/moffitt/testing1/non_diseases/')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNztUvOEgIwD",
        "outputId": "723e7851-40ee-48f8-be4f-3ed7a7b7cc83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   Image_Path       Label\n",
            "0         disease_23T (7).jpg     Disease\n",
            "1         disease_72T (4).jpg     Disease\n",
            "2         disease_92T (4).jpg     Disease\n",
            "3          disease_92 (4).jpg     Disease\n",
            "4           disease_4 (9).jpg     Disease\n",
            "...                       ...         ...\n",
            "3115  non_disease_71T (3).jpg  No Disease\n",
            "3116   non_disease_34 (3).jpg  No Disease\n",
            "3117  non_disease_69T (5).jpg  No Disease\n",
            "3118  non_disease_50T (5).jpg  No Disease\n",
            "3119   non_disease_2T (2).jpg  No Disease\n",
            "\n",
            "[3120 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Directories\n",
        "TRAINING_DISEASES_DIR = \"/content/drive/MyDrive/moffitt/training1/diseases/\"\n",
        "TRAINING_NO_DISEASES_DIR = \"/content/drive/MyDrive/moffitt/training1/non_diseases/\"\n",
        "\n",
        "# Function to get image paths and labels\n",
        "def get_image_paths_and_labels(directory, label):\n",
        "  if label==\"Disease\":\n",
        "    image_paths = [\"disease_\"+ img for img in os.listdir(directory)]\n",
        "  else:\n",
        "    image_paths = [\"non_disease_\"+ img for img in os.listdir(directory)]\n",
        "  labels = [label] * len(image_paths)\n",
        "  return image_paths, labels\n",
        "\n",
        "# Creating DataFrame for diseases\n",
        "diseases_train_paths, diseases_train_labels = get_image_paths_and_labels(TRAINING_DISEASES_DIR, label=\"Disease\")\n",
        "diseases_df = pd.DataFrame({'Image_Path': diseases_train_paths,\n",
        "                            'Label': diseases_train_labels})\n",
        "\n",
        "# Creating DataFrame for no diseases\n",
        "no_diseases_train_paths, no_diseases_train_labels = get_image_paths_and_labels(TRAINING_NO_DISEASES_DIR, label=\"No Disease\")\n",
        "no_diseases_df = pd.DataFrame({'Image_Path': no_diseases_train_paths ,\n",
        "                               'Label': no_diseases_train_labels })\n",
        "\n",
        "# Concatenating both DataFrames\n",
        "full_df2 = pd.concat([diseases_df, no_diseases_df], ignore_index=True)\n",
        "# Save the DataFrame to the same directory as training\n",
        "output_df_path = os.path.join(\"/content/drive/MyDrive/moffitt/\", \"full_df.csv\")\n",
        "full_df2.to_csv(output_df_path, index=False)\n",
        "# Display the DataFrame\n",
        "print(full_df2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kn1R2L0-oqw",
        "outputId": "acf74257-f3d8-4e4e-d921-d0bc333257f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of files in combined directory: 1914\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of files in combined directory:\", len(os.listdir('/content/drive/MyDrive/moffitt/training_combined/')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMx_pePuJVQR"
      },
      "source": [
        "Check that the training and test sets are the expected lengths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl8sQpM1O9xK",
        "outputId": "3c0685da-3fda-4b48-9bb4-467d30d5b562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training diseases images 1603\n",
            "Number of training no diseases images 1517\n",
            "Number of testing diseases images 85\n",
            "Number of testing no diseases images 80\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Number of training diseases images\", len(os.listdir('/tmp/diseases-v-nondiseases/training/diseases')))\n",
        "print(\"Number of training no diseases images\", len(os.listdir('/tmp/diseases-v-nondiseases/training/non_diseases')))\n",
        "print(\"Number of testing diseases images\", len(os.listdir('/tmp/diseases-v-nondiseases/testing/diseases/')))\n",
        "print(\"Number of testing no diseases images\", len(os.listdir('/tmp/diseases-v-nondiseases/testing/non_diseases/')))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ek-iVwoIr05f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12526ddd-1a3c-42a8-81db-d6f09d44afa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files in combined directory: 3120\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Set source directories\n",
        "non_diseases_directory = '/content/drive/MyDrive/moffitt/training1/non_diseases/'\n",
        "diseases_directory = '/content/drive/MyDrive/moffitt/training1/diseases/'\n",
        "\n",
        "# Set destination directory\n",
        "combined_directory = '/content/drive/MyDrive/moffitt/training_combined/'\n",
        "\n",
        "# Create the combined directory if it doesn't exist\n",
        "os.makedirs(combined_directory, exist_ok=True)\n",
        "\n",
        "# Copy contents of non_diseases_directory to combined_directory\n",
        "for filename in os.listdir(non_diseases_directory):\n",
        "    source_file = os.path.join(non_diseases_directory, filename)\n",
        "    destination_file = os.path.join(combined_directory, \"non_disease_\"+filename)\n",
        "    shutil.copyfile(source_file, destination_file)\n",
        "\n",
        "# Copy contents of diseases_directory to combined_directory\n",
        "for filename in os.listdir(diseases_directory):\n",
        "    source_file = os.path.join(diseases_directory, filename)\n",
        "    destination_file = os.path.join(combined_directory, \"disease_\"+filename)\n",
        "    shutil.copyfile(source_file, destination_file)\n",
        "\n",
        "# Check the combined directory\n",
        "print(\"Number of files in combined directory:\", len(os.listdir(combined_directory)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMM7o-QyY62i"
      },
      "source": [
        "### K fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-layer-normalization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qVu-HEUnpAG",
        "outputId": "48b815ea-ab24-432d-a3f8-5137bd7bcc8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-layer-normalization\n",
            "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-layer-normalization) (1.25.2)\n",
            "Building wheels for collected packages: keras-layer-normalization\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4653 sha256=0349c2697b5012543490433b949087ec9ef23aa420fb8e507bbbd14c12e0bbb7\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/3a/4b/21db23c0cc56c4b219616e181f258eb7c57d36cc5d056fae9a\n",
            "Successfully built keras-layer-normalization\n",
            "Installing collected packages: keras-layer-normalization\n",
            "Successfully installed keras-layer-normalization-0.16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPyF1f192rCt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os.path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gc\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "%matplotlib inline\n",
        "from keras.applications import ResNet50,ResNet101\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "from keras import applications\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6n7-5Gi2rF6"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold , KFold ,RepeatedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEwbdDTq2rH-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "306b8e86-b6d6-4abb-94ec-e270b031ab19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Image_Path    Label\n",
              "0  disease_23T (7).jpg  Disease\n",
              "1  disease_72T (4).jpg  Disease\n",
              "2  disease_92T (4).jpg  Disease\n",
              "3   disease_92 (4).jpg  Disease\n",
              "4    disease_4 (9).jpg  Disease"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a684955b-fecd-433a-94cf-334621043036\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image_Path</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>disease_23T (7).jpg</td>\n",
              "      <td>Disease</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>disease_72T (4).jpg</td>\n",
              "      <td>Disease</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>disease_92T (4).jpg</td>\n",
              "      <td>Disease</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>disease_92 (4).jpg</td>\n",
              "      <td>Disease</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>disease_4 (9).jpg</td>\n",
              "      <td>Disease</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a684955b-fecd-433a-94cf-334621043036')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a684955b-fecd-433a-94cf-334621043036 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a684955b-fecd-433a-94cf-334621043036');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e5b77258-ebc1-4671-8558-782a98f18829\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e5b77258-ebc1-4671-8558-782a98f18829')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e5b77258-ebc1-4671-8558-782a98f18829 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train",
              "summary": "{\n  \"name\": \"train\",\n  \"rows\": 3120,\n  \"fields\": [\n    {\n      \"column\": \"Image_Path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3120,\n        \"samples\": [\n          \"non_disease_45T (7).jpg\",\n          \"non_disease_87T.jpg\",\n          \"non_disease_13 (2).jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No Disease\",\n          \"Disease\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/moffitt/full_df.csv')\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9W5j9ahZ2rKb"
      },
      "outputs": [],
      "source": [
        "df = train.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zClB9sJv2rNN"
      },
      "outputs": [],
      "source": [
        "Disease = train[train[\"Label\"]=='Disease']\n",
        "No_Disease = train[train[\"Label\"]=='No Disease']\n",
        "\n",
        "\n",
        "df = pd.concat([df,Disease])\n",
        "df = pd.concat([df,No_Disease])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrkhE-SX2rPm"
      },
      "outputs": [],
      "source": [
        "TRAIN_PATH = '/content/drive/MyDrive/moffitt/training_combined/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPlMh2zhguSy"
      },
      "outputs": [],
      "source": [
        "from keras.layers import BatchNormalization\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "def get_model(IMG_SIZE):\n",
        "    base_model =applications.ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    add_model = Sequential()\n",
        "    add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "    add_model.add(Dropout(0.3))\n",
        "    add_model.add(Dense(64, activation='relu'))\n",
        "    add_model.add(Dropout(0.4))\n",
        "\n",
        "    add_model.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "#     model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQpGikk4wfDM"
      },
      "outputs": [],
      "source": [
        "# Storing the average of all predictions\n",
        "\n",
        "main_pred = []\n",
        "data_kfold = pd.DataFrame()\n",
        "\n",
        "# Creating X, Y for training\n",
        "\n",
        "train_y = df.Label\n",
        "train_x = df.drop(['Label'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58ywM8UE4x8t"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 150\n",
        "BATCH_SIZE = 20\n",
        "EPOCHS = 10\n",
        "N_SPLIT = 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YScvkmea4yC1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1680176-36a2-4a07-e049-bd4d9760a5a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5616 validated image filenames belonging to 2 classes.\n",
            "Found 624 validated image filenames belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 6s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "<ipython-input-14-9b4374f621f8>:36: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model_test.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "280/280 [==============================] - 1780s 6s/step - loss: 1.0553 - accuracy: 0.5888 - val_loss: 0.6945 - val_accuracy: 0.4856\n",
            "Epoch 2/10\n",
            "280/280 [==============================] - 310s 1s/step - loss: 0.6938 - accuracy: 0.5029 - val_loss: 0.6968 - val_accuracy: 0.5096\n",
            "Epoch 3/10\n",
            "280/280 [==============================] - 298s 1s/step - loss: 0.6934 - accuracy: 0.5018 - val_loss: 0.6928 - val_accuracy: 0.5144\n",
            "Epoch 4/10\n",
            "280/280 [==============================] - 290s 1s/step - loss: 0.6940 - accuracy: 0.5007 - val_loss: 0.6927 - val_accuracy: 0.5144\n",
            "Epoch 5/10\n",
            "280/280 [==============================] - 285s 1s/step - loss: 0.6935 - accuracy: 0.5054 - val_loss: 0.6928 - val_accuracy: 0.5144\n",
            "Epoch 6/10\n",
            "280/280 [==============================] - 290s 1s/step - loss: 0.6936 - accuracy: 0.5122 - val_loss: 0.6931 - val_accuracy: 0.5144\n",
            "Epoch 7/10\n",
            "280/280 [==============================] - 307s 1s/step - loss: 0.6934 - accuracy: 0.4995 - val_loss: 0.6934 - val_accuracy: 0.5144\n",
            "Epoch 8/10\n",
            "280/280 [==============================] - 312s 1s/step - loss: 0.6935 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5144\n",
            "Epoch 9/10\n",
            "280/280 [==============================] - 334s 1s/step - loss: 0.6934 - accuracy: 0.5064 - val_loss: 0.6932 - val_accuracy: 0.4856\n",
            "Epoch 10/10\n",
            "280/280 [==============================] - 329s 1s/step - loss: 0.6940 - accuracy: 0.4977 - val_loss: 0.6927 - val_accuracy: 0.5144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1 saved to /content/drive/MyDrive/moffitt/model/model_1.h5\n",
            "Found 5616 validated image filenames belonging to 2 classes.\n",
            "Found 624 validated image filenames belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "<ipython-input-14-9b4374f621f8>:36: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model_test.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "280/280 [==============================] - 360s 1s/step - loss: 64.3120 - accuracy: 0.8297 - val_loss: 14.8223 - val_accuracy: 0.5962\n",
            "Epoch 2/10\n",
            "280/280 [==============================] - 350s 1s/step - loss: 0.4916 - accuracy: 0.8878 - val_loss: 0.3460 - val_accuracy: 0.8510\n",
            "Epoch 3/10\n",
            "280/280 [==============================] - 345s 1s/step - loss: 19.8715 - accuracy: 0.8411 - val_loss: 2752.9338 - val_accuracy: 0.8654\n",
            "Epoch 4/10\n",
            "280/280 [==============================] - 335s 1s/step - loss: 18.1514 - accuracy: 0.5118 - val_loss: 0.6928 - val_accuracy: 0.5144\n",
            "Epoch 5/10\n",
            "280/280 [==============================] - 345s 1s/step - loss: 0.6935 - accuracy: 0.5100 - val_loss: 0.6938 - val_accuracy: 0.5144\n",
            "Epoch 6/10\n",
            "280/280 [==============================] - 342s 1s/step - loss: 0.6936 - accuracy: 0.5123 - val_loss: 0.6927 - val_accuracy: 0.5144\n",
            "Epoch 7/10\n",
            "280/280 [==============================] - ETA: 0s - loss: 0.6916 - accuracy: 0.5139"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "# Specify the directory to save the models\n",
        "save_dir = '/content/drive/MyDrive/moffitt/model/'\n",
        "\n",
        "# Check if the directory exists, if not, create it\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=N_SPLIT,shuffle=True,random_state=42)\n",
        "j = 0\n",
        "for train_idx, val_idx in list(kfold.split(train_x,train_y)):\n",
        "    x_train_df = df.iloc[train_idx]\n",
        "    x_valid_df = df.iloc[val_idx]\n",
        "    j+=1\n",
        "\n",
        "\n",
        "    training_set = train_datagen.flow_from_dataframe(dataframe=x_train_df, directory=TRAIN_PATH,\n",
        "                                                 x_col=\"Image_Path\", y_col=\"Label\",\n",
        "                                                 class_mode=\"categorical\",\n",
        "                                                 target_size=(IMG_SIZE,IMG_SIZE), batch_size=BATCH_SIZE)\n",
        "\n",
        "    validation_set = validation_datagen.flow_from_dataframe(dataframe=x_valid_df, directory=TRAIN_PATH,\n",
        "                                                 x_col=\"Image_Path\", y_col=\"Label\",\n",
        "                                                 class_mode=\"categorical\",\n",
        "                                                 target_size=(IMG_SIZE,IMG_SIZE), batch_size=BATCH_SIZE)\n",
        "\n",
        "    model_test = get_model(IMG_SIZE)\n",
        "\n",
        "\n",
        "    history = model_test.fit_generator(\n",
        "        training_set,\n",
        "        validation_data=validation_set,\n",
        "        epochs=EPOCHS,\n",
        "        steps_per_epoch=x_train_df.shape[0] // BATCH_SIZE,\n",
        "    )\n",
        "    # Save the model after training\n",
        "    model_filename = f'model_{j}.h5'\n",
        "    model_path = os.path.join(save_dir, model_filename)\n",
        "    model_test.save(model_path)\n",
        "    print(f\"Model {j} saved to {model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Djx8U6q74yFU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "f2620945-85ae-4df1-ce7e-46833d3622f2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "No file or directory found at your_model.h5",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-023156db224c>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the entire model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'your_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load the model architecture from JSON and load the learned weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             raise IOError(\n\u001b[0m\u001b[1;32m    235\u001b[0m                                 \u001b[0;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                             )\n",
            "\u001b[0;31mOSError\u001b[0m: No file or directory found at your_model.h5"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load the entire model\n",
        "loaded_model = load_model('your_model.h5')\n",
        "\n",
        "# Load the model architecture from JSON and load the learned weights\n",
        "with open('your_model.json', 'r') as json_file:\n",
        "    loaded_model_json = json_file.read()\n",
        "\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "loaded_model.load_weights('your_model_weights.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWqUV0Mb4yII"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJsld68igT7m"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = (150, 150)\n",
        "k_folds=10\n",
        "\n",
        "core_idg = ImageDataGenerator(samplewise_center=True,\n",
        "                              samplewise_std_normalization=True,\n",
        "                              horizontal_flip = True,\n",
        "                              vertical_flip = False,\n",
        "                              height_shift_range= 0.05,\n",
        "                              width_shift_range=0.1,\n",
        "                              rotation_range=5,\n",
        "                              shear_range = 0.1,\n",
        "                              fill_mode = 'reflect',\n",
        "                              zoom_range=0.15)\n",
        "\n",
        "# Training with K-fold cross validation\n",
        "kf = KFold(n_splits=k_folds, random_state=None, shuffle=True)\n",
        "X= np.array(full_df2['Image_Path'])\n",
        "i = 1\n",
        "for train_index, test_index in kf.split(X):\n",
        "    trainData = X[train_index]\n",
        "    testData = X[test_index]\n",
        "    ## create train, valid dataframe and thus train_gen , valid_gen for each fold-loop\n",
        "    train_df = full_df2.loc[full_df2['Image_Path'].isin(list(trainData))]\n",
        "    valid_df = full_df2.loc[full_df2['Image_Path'].isin(list(testData))]\n",
        "    #create model object\n",
        "    all_labels = [ \"Diseases\" , \"No Diseases\" ]\n",
        "    train_gen = core_idg.flow_from_dataframe(dataframe=train_df,\n",
        "                                         directory=\"None\",\n",
        "                                         x_col = 'Image_Path',\n",
        "                                         y_col = 'Label',\n",
        "                                         class_mode = 'categorical',\n",
        "                                         classes = all_labels,\n",
        "                                         target_size = IMG_SIZE,\n",
        "                                         color_mode = 'rgb',\n",
        "                                         batch_size = 64)\n",
        "    valid_gen = core_idg.flow_from_dataframe(dataframe=valid_df,\n",
        "                                         directory=\"None\",\n",
        "                                         x_col = 'Image_Path',\n",
        "                                         y_col = 'Label',\n",
        "                                         class_mode = 'categorical',\n",
        "                                         classes = all_labels,\n",
        "                                         target_size = IMG_SIZE,\n",
        "                                         color_mode = 'rgb',\n",
        "                                         batch_size = 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKmykh0Uso_c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C43YfB8qspCY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YdkxhDkspFO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNz89__rJVQR"
      },
      "source": [
        "### Data augmentation (try adjusting the parameters)!\n",
        "\n",
        "Here, you'll use the `ImageDataGenerator` to perform data augmentation.  \n",
        "- Things like rotating and flipping the existing images allows you to generate training data that is more varied, and can help the model generalize better during training.  \n",
        "- You can also use the data generator to apply data augmentation to the validation set.\n",
        "\n",
        "You can use the default parameter values for a first pass through this lab.\n",
        "- Later, try to experiment with the parameters of `ImageDataGenerator` to improve the model's performance.\n",
        "- Try to drive reach 99.9% validation accuracy or better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jGuBfZtOPJn"
      },
      "outputs": [],
      "source": [
        "!rm -rf VALIDATION_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVO1l8vAPE14"
      },
      "outputs": [],
      "source": [
        "\n",
        "TRAINING_DIR = \"/tmp/diseases-v-nondiseases/trainingkfolds/\"\n",
        "# Experiment with your own parameters to reach 99.9% validation accuracy or better\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
        "                                                    batch_size=10,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150))\n",
        "\n",
        "VALIDATION_DIR = \"/tmp/diseases-v-nondiseases/validationkfolds/\"\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
        "                                                              batch_size=40,\n",
        "                                                              class_mode='binary',\n",
        "                                                              target_size=(150, 150))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WchwDzWNJVQR"
      },
      "source": [
        "### Get and prepare the model\n",
        "\n",
        "You'll be using the `InceptionV3` model.  \n",
        "- Since you're making use of transfer learning, you'll load the pre-trained weights of the model.\n",
        "- You'll also freeze the existing layers so that they aren't trained on your downstream task with the data.\n",
        "- You'll also get a reference to the last layer, 'mixed7' because you'll add some layers after this last layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiPK1LlMOvm7"
      },
      "outputs": [],
      "source": [
        "weights_url = \"https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
        "weights_file = \"inception_v3.h5\"\n",
        "urllib.request.urlretrieve(weights_url, weights_file)\n",
        "\n",
        "# Instantiate the model\n",
        "pre_trained_model = InceptionV3(input_shape=(150, 150, 3),\n",
        "                                include_top=False,\n",
        "                                weights=None)\n",
        "\n",
        "# load pre-trained weights\n",
        "pre_trained_model.load_weights(weights_file)\n",
        "\n",
        "# freeze the layers\n",
        "for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# pre_trained_model.summary()\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3edBz_IxJVQR"
      },
      "source": [
        "### Add layers\n",
        "Add some layers that you will train on the cats and dogs data.\n",
        "- `Flatten`: This will take the output of the `last_layer` and flatten it to a vector.\n",
        "- `Dense`: You'll add a dense layer with a relu activation.\n",
        "- `Dense`: After that, add a dense layer with a sigmoid activation.  The sigmoid will scale the output to range from 0 to 1, and allow you to interpret the output as a prediction between two categories.\n",
        "\n",
        "Then create the model object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDidHXO1JVQR"
      },
      "outputs": [],
      "source": [
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(pre_trained_model.input, x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asCm8okXJVQR"
      },
      "source": [
        "### Train the model\n",
        "Compile the model, and then train it on the test data using `model.fit`\n",
        "- Feel free to adjust the number of epochs.  This project was originally designed with 20 epochs.\n",
        "- For the sake of time, you can use fewer epochs (2) to see how the code runs.\n",
        "- You can ignore the warnings about some of the images having corrupt EXIF data. Those will be skipped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nxUncKWPRhR"
      },
      "outputs": [],
      "source": [
        "\n",
        "# compile the model\n",
        "model.compile(optimizer=RMSprop(lr=0.0001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "# train the model (adjust the number of epochs from 1 to improve performance)\n",
        "history = model.fit(\n",
        "            train_generator,\n",
        "            validation_data=validation_generator,\n",
        "            epochs=15,\n",
        "            verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6Oo6kM-JVQR"
      },
      "source": [
        "### Visualize the training and validation accuracy\n",
        "\n",
        "You can see how the training and validation accuracy change with each epoch on an x-y plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erDopoQ5eNL7"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history.history['acc']\n",
        "val_acc=history.history['val_acc']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.figure()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKc_1Qm8JVQR"
      },
      "source": [
        "### Predict on a test image\n",
        "\n",
        "You can upload any image and have the model predict whether it's a disease image or a no disease image.\n",
        "- Find an image of a disease or no disease\n",
        "- Run the following code cell.  It will ask you to upload an image.\n",
        "- The model will print \"is a disease image\" or \"is a no disease image\" depending on the model's prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0R9fsf4w29e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "os.chdir('/content/')\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = load_img(path, target_size=(150, 150))\n",
        "  x = img_to_array(img)\n",
        "  x /= 255\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  image_tensor = np.vstack([x])\n",
        "  classes = model.predict(image_tensor)\n",
        "  print(classes[0])\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is no disease\")\n",
        "  else:\n",
        "    print(fn + \" is disease\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}